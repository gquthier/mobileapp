#!/usr/bin/env node

/**
 * Test de transcription de vid√©o depuis URL avec l'API OpenAI Whisper
 * Simule exactement le processus de votre application mobile
 */

require('dotenv').config();
const fetch = require('node-fetch'); // npm install node-fetch@2
const FormData = require('form-data');
const fs = require('fs');
const path = require('path');

async function testVideoTranscriptionFromURL() {
  console.log('üé¨ TEST DE TRANSCRIPTION VID√âO DEPUIS URL');
  console.log('==========================================');

  // 1. V√©rifier la cl√© API
  const apiKey = process.env.EXPO_PUBLIC_OPENAI_API_KEY;
  if (!apiKey) {
    console.error('‚ùå Cl√© OpenAI manquante dans .env');
    console.log('üí° Ajoutez: EXPO_PUBLIC_OPENAI_API_KEY=sk-proj-...');
    return;
  }
  console.log('‚úÖ Cl√© API trouv√©e:', apiKey.substring(0, 15) + '...');

  // 2. URL de test - vid√©o courte publique
  // Vous pouvez remplacer par l'URL de votre vid√©o Supabase
  const VIDEO_TEST_URLS = [
    // Exemple d'URL publique courte (remplacez par la v√¥tre)
    'https://sample-videos.com/zip/10/mp4/SampleVideo_1280x720_1mb.mp4',
    // Ou ajoutez directement l'URL de votre vid√©o Supabase ici :
    // 'https://votre-projet.supabase.co/storage/v1/object/public/videos/votre-video.mp4'
  ];

  for (const videoUrl of VIDEO_TEST_URLS) {
    console.log('\nüîó Test avec URL:', videoUrl);

    try {
      // 3. T√©l√©charger la vid√©o (comme fait dans votre app)
      console.log('üì• T√©l√©chargement de la vid√©o...');

      const videoResponse = await fetch(videoUrl);
      if (!videoResponse.ok) {
        console.error('‚ùå Impossible de t√©l√©charger la vid√©o:', videoResponse.status);
        continue;
      }

      const contentLength = videoResponse.headers.get('content-length');
      const contentType = videoResponse.headers.get('content-type');

      console.log('‚úÖ Vid√©o accessible:', {
        status: videoResponse.status,
        contentType: contentType,
        size: contentLength ? `${(parseInt(contentLength) / 1024 / 1024).toFixed(2)}MB` : 'unknown'
      });

      // 4. V√©rifier la taille (limite 25MB pour OpenAI)
      if (contentLength && parseInt(contentLength) > 25 * 1024 * 1024) {
        console.error('‚ùå Vid√©o trop volumineuse pour OpenAI (>25MB)');
        continue;
      }

      // 5. Obtenir le buffer de la vid√©o
      const videoBuffer = await videoResponse.buffer();
      console.log('üìÅ Vid√©o t√©l√©charg√©e:', `${(videoBuffer.length / 1024 / 1024).toFixed(2)}MB`);

      // 6. Pr√©parer le FormData (EXACTEMENT comme dans votre code React Native)
      console.log('üì¶ Pr√©paration du FormData...');

      const formData = new FormData();

      // M√âTHODE CORRECTE pour envoyer un buffer comme fichier
      formData.append('file', videoBuffer, {
        filename: 'video.mp4',
        contentType: 'video/mp4'
      });

      formData.append('model', 'whisper-1');
      formData.append('language', 'fr'); // Fran√ßais comme dans votre app
      formData.append('response_format', 'verbose_json');
      formData.append('temperature', '0.2');

      console.log('üì§ Envoi √† l\'API OpenAI Whisper...');

      // 7. Appel API (identique √† votre code)
      const transcriptionResponse = await fetch('https://api.openai.com/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          ...formData.getHeaders()
        },
        body: formData
      });

      console.log('üì® R√©ponse OpenAI:', transcriptionResponse.status, transcriptionResponse.statusText);

      // 8. Traiter la r√©ponse
      if (!transcriptionResponse.ok) {
        const errorText = await transcriptionResponse.text();
        console.error('‚ùå ERREUR OPENAI API:');
        console.error('   Status:', transcriptionResponse.status);
        console.error('   Response:', errorText);

        // Diagnostics sp√©cifiques
        if (transcriptionResponse.status === 400) {
          console.log('üîç DIAGNOSTIC 400:');
          console.log('   - V√©rifiez le format de fichier (MP4/MP3/WAV support√©s)');
          console.log('   - V√©rifiez que le fichier n\'est pas corrompu');
          console.log('   - Param√®tres FormData incorrects');
        } else if (transcriptionResponse.status === 401) {
          console.log('üîç DIAGNOSTIC 401: Cl√© API invalide ou expir√©e');
        } else if (transcriptionResponse.status === 413) {
          console.log('üîç DIAGNOSTIC 413: Fichier > 25MB');
        } else if (transcriptionResponse.status === 429) {
          console.log('üîç DIAGNOSTIC 429: Rate limit atteint');
        }
      } else {
        // SUCC√àS !
        const result = await transcriptionResponse.json();
        console.log('üéâ TRANSCRIPTION R√âUSSIE !');
        console.log('‚úÖ R√©sultat:');
        console.log('   Langue d√©tect√©e:', result.language);
        console.log('   Dur√©e:', result.duration + 's');
        console.log('   Longueur du texte:', result.text.length);
        console.log('   Segments:', result.segments?.length || 0);
        console.log('\nüìù TEXTE TRANSCRIT:');
        console.log('   "' + result.text.substring(0, 200) + '..."');

        if (result.segments && result.segments.length > 0) {
          console.log('\n‚è±Ô∏è PREMIERS SEGMENTS:');
          result.segments.slice(0, 3).forEach((segment, i) => {
            console.log(`   ${i+1}. [${segment.start}s-${segment.end}s]: "${segment.text}"`);
          });
        }

        // Sauvegarder le r√©sultat pour debug
        const resultFile = `transcription-result-${Date.now()}.json`;
        fs.writeFileSync(resultFile, JSON.stringify(result, null, 2));
        console.log('\nüíæ R√©sultat sauvegard√© dans:', resultFile);
      }

    } catch (error) {
      console.error('‚ùå ERREUR GLOBALE:', error.message);
      console.error('Stack:', error.stack);
    }
  }

  console.log('\nüèÅ Test termin√©');
}

// Fonction pour tester avec une URL sp√©cifique
async function testWithCustomURL(url) {
  if (!url) {
    console.log('\nüí° USAGE:');
    console.log('node test-video-transcription.js');
    console.log('ou avec URL sp√©cifique:');
    console.log('node test-video-transcription.js "https://votre-url-video.mp4"');
    return;
  }

  console.log('üéØ Test avec URL personnalis√©e:', url);

  // Test direct avec l'URL fournie
  await testSingleVideoURL(url);
}

// Fonction pour tester une seule URL
async function testSingleVideoURL(videoUrl) {
  console.log('üé¨ TEST DE TRANSCRIPTION VID√âO DEPUIS URL');
  console.log('==========================================');

  // 1. V√©rifier la cl√© API
  const apiKey = process.env.EXPO_PUBLIC_OPENAI_API_KEY;
  if (!apiKey) {
    console.error('‚ùå Cl√© OpenAI manquante dans .env');
    console.log('üí° Ajoutez: EXPO_PUBLIC_OPENAI_API_KEY=sk-proj-...');
    return;
  }
  console.log('‚úÖ Cl√© API trouv√©e:', apiKey.substring(0, 15) + '...');

  console.log('\nüîó Test avec URL:', videoUrl);

  try {
    // 3. T√©l√©charger la vid√©o (comme fait dans votre app)
    console.log('üì• T√©l√©chargement de la vid√©o...');

    const videoResponse = await fetch(videoUrl);
    if (!videoResponse.ok) {
      console.error('‚ùå Impossible de t√©l√©charger la vid√©o:', videoResponse.status);
      return;
    }

    const contentLength = videoResponse.headers.get('content-length');
    const contentType = videoResponse.headers.get('content-type');

    console.log('‚úÖ Vid√©o accessible:', {
      status: videoResponse.status,
      contentType: contentType,
      size: contentLength ? `${(parseInt(contentLength) / 1024 / 1024).toFixed(2)}MB` : 'unknown'
    });

    // 4. V√©rifier la taille (limite 25MB pour OpenAI)
    if (contentLength && parseInt(contentLength) > 25 * 1024 * 1024) {
      console.error('‚ùå Vid√©o trop volumineuse pour OpenAI (>25MB)');
      return;
    }

    // 5. Obtenir le buffer de la vid√©o
    const videoBuffer = await videoResponse.buffer();
    console.log('üìÅ Vid√©o t√©l√©charg√©e:', `${(videoBuffer.length / 1024 / 1024).toFixed(2)}MB`);

    // 6. Pr√©parer le FormData (EXACTEMENT comme dans votre code React Native)
    console.log('üì¶ Pr√©paration du FormData...');

    const formData = new FormData();

    // M√âTHODE CORRECTE pour envoyer un buffer comme fichier
    formData.append('file', videoBuffer, {
      filename: 'video.mp4',
      contentType: 'video/mp4'
    });

    formData.append('model', 'whisper-1');
    formData.append('language', 'fr'); // Fran√ßais comme dans votre app
    formData.append('response_format', 'verbose_json');
    formData.append('temperature', '0.2');

    console.log('üì§ Envoi √† l\'API OpenAI Whisper...');

    // 7. Appel API (identique √† votre code)
    const transcriptionResponse = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        ...formData.getHeaders()
      },
      body: formData
    });

    console.log('üì® R√©ponse OpenAI:', transcriptionResponse.status, transcriptionResponse.statusText);

    // 8. Traiter la r√©ponse
    if (!transcriptionResponse.ok) {
      const errorText = await transcriptionResponse.text();
      console.error('‚ùå ERREUR OPENAI API:');
      console.error('   Status:', transcriptionResponse.status);
      console.error('   Response:', errorText);

      // Diagnostics sp√©cifiques
      if (transcriptionResponse.status === 400) {
        console.log('üîç DIAGNOSTIC 400:');
        console.log('   - V√©rifiez le format de fichier (MP4/MP3/WAV support√©s)');
        console.log('   - V√©rifiez que le fichier n\'est pas corrompu');
        console.log('   - Param√®tres FormData incorrects');
      } else if (transcriptionResponse.status === 401) {
        console.log('üîç DIAGNOSTIC 401: Cl√© API invalide ou expir√©e');
      } else if (transcriptionResponse.status === 413) {
        console.log('üîç DIAGNOSTIC 413: Fichier > 25MB');
      } else if (transcriptionResponse.status === 429) {
        console.log('üîç DIAGNOSTIC 429: Rate limit atteint');
      }
    } else {
      // SUCC√àS !
      const result = await transcriptionResponse.json();
      console.log('üéâ TRANSCRIPTION R√âUSSIE !');
      console.log('‚úÖ R√©sultat:');
      console.log('   Langue d√©tect√©e:', result.language);
      console.log('   Dur√©e:', result.duration + 's');
      console.log('   Longueur du texte:', result.text.length);
      console.log('   Segments:', result.segments?.length || 0);
      console.log('\nüìù TEXTE TRANSCRIT:');
      console.log('   "' + result.text.substring(0, 200) + '..."');

      if (result.segments && result.segments.length > 0) {
        console.log('\n‚è±Ô∏è PREMIERS SEGMENTS:');
        result.segments.slice(0, 3).forEach((segment, i) => {
          console.log(`   ${i+1}. [${segment.start}s-${segment.end}s]: "${segment.text}"`);
        });
      }

      // Sauvegarder le r√©sultat pour debug
      const resultFile = `transcription-result-${Date.now()}.json`;
      fs.writeFileSync(resultFile, JSON.stringify(result, null, 2));
      console.log('\nüíæ R√©sultat sauvegard√© dans:', resultFile);
    }

  } catch (error) {
    console.error('‚ùå ERREUR GLOBALE:', error.message);
    console.error('Stack:', error.stack);
  }

  console.log('\nüèÅ Test termin√©');
}

// Point d'entr√©e
const customUrl = process.argv[2];
if (customUrl) {
  testWithCustomURL(customUrl);
} else {
  testVideoTranscriptionFromURL();
}